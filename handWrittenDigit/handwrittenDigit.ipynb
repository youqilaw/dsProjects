{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Summary\n",
    "\n",
    "In this project, we use the handwritten digit dataset to conduct classification with neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "# 1. Basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 2. Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Reshape\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation(data,\n",
    "                    fold = 5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Summary:\n",
    "    This is the function that takes the data and model as input. \n",
    "    It conducts cross validation. \n",
    "    \n",
    "    Args:\n",
    "    data: pandas dataframe\n",
    "    model: Model for validation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create index for cross validation\n",
    "    splits = np.array_split(data.sample(frac = 1), fold)\n",
    "    \n",
    "    # start the cross validation\n",
    "    for i in range(fold):\n",
    "        \n",
    "        # split data\n",
    "        train = splits.copy()\n",
    "        test = splits[i]\n",
    "        del train[i]\n",
    "        train = pd.concat(train, sort = False)\n",
    "        \n",
    "        # Training and testing\n",
    "        model = trainNN(train, \n",
    "                        isCNN = False)\n",
    "        validateNN(test, model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a function to train a neural network model\n",
    "\n",
    "def trainNN(trainingSet,\n",
    "            isCNN = 0,\n",
    "            loss = 'categorical_crossentropy', \n",
    "            optimizer = 'adam', \n",
    "            epochs = 5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Summary:\n",
    "    This function trains the model from the given training data\n",
    "    \n",
    "    Args:\n",
    "    X_training: pandas dataframe, predictors\n",
    "    y_training: pandas dataframe, response\n",
    "    isCNN: int, indicating whether this is an CNN\n",
    "    loss: string, loss function - refer to Keras documentation\n",
    "    optimizer: string, optimization algorithm - refer to Keras documentation.\n",
    "        'adam', 'SGD', 'RMSprop', etc.,\n",
    "    epochs: int, epochs times\n",
    "    \n",
    "    Note: Third argument is created as the input dimension differs. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Data preprocessing - Normalize feature\n",
    "    (X_train, y_train) = trainingSet[trainingSet.columns.difference(['label'])], trainingSet['label'] \n",
    "    # X_train = (X_train / 255).values.reshape(X_train.shape[0], 28, 28, 1)\n",
    "    X_train = (X_train / 255).values\n",
    "    \n",
    "    # Data preprocessing - Hot encoding\n",
    "    y_train = to_categorical(y_train)\n",
    "\n",
    "    # Start with input dimension\n",
    "    if isCNN == 1:\n",
    "        inputDim = X_train.shape[1:4]\n",
    "    else:\n",
    "        inputDim = X_train.shape[1]\n",
    "        \n",
    "    # Neural Network Structure\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim = inputDim))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Neural Network Training Specification\n",
    "    model.compile(loss = loss,\n",
    "                  optimizer = optimizer,\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, \n",
    "              y_train, \n",
    "              epochs = epochs,\n",
    "              verbose = False)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateNN(testingSet,\n",
    "               model):\n",
    "    \n",
    "    \"\"\"\n",
    "    X_testing: pandas dataframe, predictors\n",
    "    y_testing: pandas dataframe, response\n",
    "    isCNN: int, indicating whether this is an CNN\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Preprocessing\n",
    "    (X_test, y_test) = testingSet[testingSet.columns.difference(['label'])], testingSet['label'] \n",
    "    # X_test = (X_test / 255).values.reshape(X_test.shape[0], 28, 28, 1)\n",
    "    X_test = (X_test / 255).values\n",
    "    \n",
    "    # Hot encoding\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    result = model.evaluate(X_test, y_test, verbose = False)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"The loss is \",\n",
    "          result[0], \"\\n\")\n",
    "    print(\"The accuracy is \",\n",
    "          result[1], \"\\n\")\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "-----------------------------------------\n",
      "The loss is  0.11363575707588877 \n",
      "\n",
      "The accuracy is  0.9670237898826599 \n",
      "\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "The loss is  0.1063876793861744 \n",
      "\n",
      "The accuracy is  0.9700000286102295 \n",
      "\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "The loss is  0.09799418065253468 \n",
      "\n",
      "The accuracy is  0.9694047570228577 \n",
      "\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "The loss is  0.08287743925604792 \n",
      "\n",
      "The accuracy is  0.9757142663002014 \n",
      "\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "The loss is  0.11147530789176623 \n",
      "\n",
      "The accuracy is  0.9664285778999329 \n",
      "\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "crossValidation(dataSet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
